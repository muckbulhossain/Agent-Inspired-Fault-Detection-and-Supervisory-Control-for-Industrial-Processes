{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65870c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell to get SHAP characteristics for the dataset (OM0-OM8)\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ==================== CONFIGURATION ====================\n",
    "DATA_DIR = r'File DIrectoty Address'----------> Put the directory address where all the necessary files are saved\n",
    "MODEL_PATH = os.path.join(DATA_DIR, 'rf_model.pkl')\n",
    "SCALER_PATH = os.path.join(DATA_DIR, 'rf_scaler.pkl')\n",
    "\n",
    "def get_shap_features():\n",
    "    # STRICT column ordering to ensure SHAP matches the model training\n",
    "    return [\n",
    "        'Data_1', 'Data_2', \n",
    "        'Data_3', 'Data_4', 'Data_5', 'Data_6', \n",
    "        'Data_7', 'Data_8', 'Data_9', 'Data10', \n",
    "        'Data_11', 'Data_12', 'Data_13', \n",
    "        'Data_14', 'Data_15', 'Data_16', 'Data_17'\n",
    "    ]\n",
    "\n",
    "# ==================== 1. LOAD RESOURCES ====================\n",
    "print(\"[INFO] Loading Model, Scaler, and Data...\")\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"[ERR] Model not found at {MODEL_PATH}\")\n",
    "    sys.exit()\n",
    "\n",
    "model = joblib.load(MODEL_PATH)\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "\n",
    "# Load the data file with nominal sensor values (OM0) to serve as the background dataset\n",
    "sample_file = os.path.join(DATA_DIR, 'OM0.xlsx')\n",
    "if not os.path.exists(sample_file):\n",
    "    print(\"[ERR] Could not find OM0.xlsx or Please ensure data exists.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Load and Preprocess\n",
    "try:\n",
    "    if sample_file.endswith('.xlsx'):\n",
    "        df = pd.read_excel(sample_file)\n",
    "    else:\n",
    "        df = pd.read_csv(sample_file, sep=';', decimal=',')\n",
    "\n",
    "    # Extract features in correct order\n",
    "    feature_cols = get_shap_features()\n",
    "    df_features = df[feature_cols].copy()\n",
    "\n",
    "    # Scale data (Safe to ignore warning)\n",
    "    X_sample = scaler.transform(df_features)\n",
    "\n",
    "    # Create Display DataFrame (so plots show column names)\n",
    "    X_display = pd.DataFrame(X_sample, columns=feature_cols)\n",
    "    print(f\"[INFO] Data loaded. Processing FULL dataset: {X_display.shape[0]} rows.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERR] Processing data failed: {e}\")\n",
    "    sys.exit()\n",
    "\n",
    "# ==================== 2. CALCULATE SHAP (FULL DATA) ====================\n",
    "print(\"[INFO] Calculating SHAP values for ALL rows (this may take time)...\")\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "shap_values = explainer.shap_values(X_display)\n",
    "\n",
    "is_list = isinstance(shap_values, list)\n",
    "if not is_list:\n",
    "    shap_array = np.array(shap_values)\n",
    "    print(f\"[DEBUG] SHAP output is an ARRAY of shape {shap_array.shape}\")\n",
    "else:\n",
    "    print(f\"[DEBUG] SHAP output is a LIST of length {len(shap_values)}\")\n",
    "\n",
    "# ==================== 3. GENERATE PLOTS (LOOP 0-8) ====================\n",
    "print(\"[INFO] Generating plots for all 9 classes...\")\n",
    "\n",
    "for i in range(9):\n",
    "    class_name = f\"OM{i}\"\n",
    "    print(f\"  > Processing {class_name}...\")\n",
    "\n",
    "    # Extract specific class data\n",
    "    if is_list:\n",
    "        if i >= len(shap_values): continue\n",
    "        to_plot = shap_values[i]\n",
    "    else:\n",
    "        \n",
    "        if len(shap_array.shape) == 3 and i < shap_array.shape[2]:\n",
    "            to_plot = shap_array[:, :, i]\n",
    "        else:\n",
    "            to_plot = shap_array \n",
    "\n",
    "    # Plot\n",
    "    plt.figure()\n",
    "    plt.title(f\"Feature Importance for {class_name} (Full Data)\")\n",
    "    \n",
    "    shap.summary_plot(to_plot, X_display, show=False)\n",
    "    \n",
    "    # Save\n",
    "    save_path = os.path.join(DATA_DIR, f'shap_summary_{class_name}.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# ==================== 4. OVERALL IMPORTANCE BAR CHART ====================\n",
    "print(\"  > Generating Overall Importance Bar Chart...\")\n",
    "plt.figure()\n",
    "\n",
    "# Use Class 0 (Normal) data structure for the bar chart\n",
    "baseline_data = shap_values[0] if is_list else (shap_array[:, :, 0] if len(shap_array.shape) == 3 else shap_array)\n",
    "\n",
    "# Using X_display\n",
    "shap.summary_plot(baseline_data, X_display, plot_type=\"bar\", show=False)\n",
    "\n",
    "plt.title(\"Overall Feature Importance Ranking (Full Data)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(DATA_DIR, 'shap_importance_bar.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\n[SUCCESS] All images saved to: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481d955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell just to train the model based on the sensor data files (OM files)\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    classification_report\n",
    ")\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==================== CONFIGURATION ====================\n",
    "DATA_DIR = r'File DIrectoty Address'----------> Put the directory address where all the necessary files are saved\n",
    "CLASS_NAMES = [f'OM{i}' for i in range(9)]\n",
    "MAX_ROWS_PER_FILE = 1200\n",
    "\n",
    "# ==================== 1. FEATURE SELECTION ====================\n",
    "def get_shap_features():\n",
    "    return [\n",
    "        'Data_1', 'Data_2', \n",
    "        'Data_3', 'Data_4', 'Data_5', 'Data_6', \n",
    "        'Data_7', 'Data_8', 'Data_9', 'Data10', \n",
    "        'Data_11', 'Data_12', 'Data_13', \n",
    "        'Data_14', 'Data_15', 'Data_16', 'Data_17'\n",
    "    ]\n",
    "\n",
    "# ==================== 2. DATA LOADING ====================\n",
    "def load_data():\n",
    "    print(f\"[DATA] Loading & Cleaning data...\")\n",
    "    X_list, y_list = [], []\n",
    "    active_cols = get_shap_features()\n",
    "    LAC_IDX, NIT_IDX = 0, 1\n",
    "\n",
    "    for class_idx, class_name in enumerate(CLASS_NAMES):\n",
    "        xlsx_path = os.path.join(DATA_DIR, f'{class_name}.xlsx')\n",
    "        csv_path = os.path.join(DATA_DIR, f'{class_name}.csv')\n",
    "        df = None\n",
    "        try:\n",
    "            if os.path.exists(csv_path):\n",
    "                df = pd.read_csv(csv_path, sep=';', decimal=',')\n",
    "            elif os.path.exists(xlsx_path):\n",
    "                df = pd.read_excel(xlsx_path)\n",
    "        except:\n",
    "            pass\n",
    "        if df is None:\n",
    "            continue\n",
    "\n",
    "        # Convert numeric-looking object columns\n",
    "        for col in df.columns:\n",
    "            if 'Time' not in col and df[col].dtype == 'object':\n",
    "                try:\n",
    "                    df[col] = (\n",
    "                        df[col].astype(str)\n",
    "                        .str.replace(',', '.')\n",
    "                        .apply(pd.to_numeric, errors='coerce')\n",
    "                    )\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        # Ensure all active columns exist\n",
    "        for c in active_cols:\n",
    "            if c not in df.columns:\n",
    "                df[c] = 0.0\n",
    "\n",
    "        df_filtered = df[active_cols].iloc[:MAX_ROWS_PER_FILE]\n",
    "        X_data = df_filtered.values\n",
    "        labels = np.full(len(df_filtered), class_idx)\n",
    "\n",
    "        # CLEANING: If value is nominal, force label to 0\n",
    "        if class_name in ['OM1', 'OM2', 'OM3', 'OM4']:\n",
    "            vals = X_data[:, LAC_IDX]\n",
    "            mask = (vals > 19.8) & (vals < 20.2)\n",
    "            labels[mask] = 0\n",
    "        elif class_name in ['OM5', 'OM6', 'OM7', 'OM8']:\n",
    "            vals = X_data[:, NIT_IDX]\n",
    "            mask = (vals > 3.9) & (vals < 4.1)\n",
    "            labels[mask] = 0\n",
    "\n",
    "        X_list.append(X_data)\n",
    "        y_list.append(labels)\n",
    "        print(f\"  âœ“ {class_name}: Loaded {len(labels)} rows\")\n",
    "\n",
    "    if not X_list:\n",
    "        return None, None\n",
    "    return np.vstack(X_list), np.hstack(y_list)\n",
    "\n",
    "# ==================== 3. TRAINING & EVALUATION ====================\n",
    "print(\"=\" * 60 + \"\\n STARTING TRAINING \\n\" + \"=\" * 60)\n",
    "X, y = load_data()\n",
    "\n",
    "if X is not None:\n",
    "    print(\"\\n[SCALER] Fitting RobustScaler...\")\n",
    "    scaler = RobustScaler().fit(X)\n",
    "    X_scaled = scaler.transform(X)\n",
    "    joblib.dump(scaler, os.path.join(DATA_DIR, 'rf_scaler.pkl'))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    print(\"[TRAIN] Training Random Forest...\")\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,\n",
    "        min_samples_leaf=4,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    joblib.dump(rf, os.path.join(DATA_DIR, 'rf_model.pkl'))\n",
    "\n",
    "    # ===== METRICS =====\n",
    "    preds = rf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds, average='weighted')  \n",
    "\n",
    "    print(f\"\\n>>> ACCURACY : {acc * 100:.2f}%\")\n",
    "    print(f\">>> F1-score : {f1 * 100:.2f}%\")\n",
    "    print(\"\\nConfusion matrix (raw values):\\n\", cm)\n",
    "    print(\"\\nClassification report:\\n\", classification_report(y_test, preds))\n",
    "\n",
    "    # ===== PLOT & SAVE CONFUSION MATRIX =====\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='Blues',\n",
    "        xticklabels=CLASS_NAMES,\n",
    "        yticklabels=CLASS_NAMES\n",
    "    )\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix (F1 = {f1*100:.2f}%)')\n",
    "    plt.tight_layout()\n",
    "    out_path = os.path.join(DATA_DIR, 'confusion_matrix_rf.jpg')\n",
    "    plt.savefig(out_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Saved confusion matrix image to:\", out_path)\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "else:\n",
    "    print(\"[ERR] No data found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ec81fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#online fault detection mode\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import paho.mqtt.client as mqtt\n",
    "from collections import deque, Counter\n",
    "import joblib\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==================== CONFIGURATION ====================\n",
    "DATA_DIR = r'File DIrectoty Address'----------> Put the directory address where all the necessary files are saved\n",
    "CLASS_NAMES = [f'OM{i}' for i in range(9)]\n",
    "WARMUP_TIME = 10.0\n",
    "\n",
    "# MQTT Settings\n",
    "MQTT_BROKER = 'localhost'\n",
    "MQTT_PORT = 1883\n",
    "LIVE_FEATURES_TOPIC = 'fault_detection/live/features'\n",
    "LIVE_RESULT_TOPIC = 'fault_detection/live/prediction'\n",
    "\n",
    "# Topics required by your Simulink setup (Bridge)\n",
    "TOPIC_CONTROL = 'fault_detection/live/control'\n",
    "TOPIC_SOFT_SENSOR = 'fault_detection/live/soft_sensor'\n",
    "\n",
    "# ==================== UTILS ====================\n",
    "def get_shap_features():\n",
    "    return [\n",
    "        'Data_1', 'Data_2', \n",
    "        'Data_3', 'Data_4', 'Data_5', 'Data_6', \n",
    "        'Data_7', 'Data_8', 'Data_9', 'Data10', \n",
    "        'Data_11', 'Data_12', 'Data_13', \n",
    "        'Data_14', 'Data_15', 'Data_16', 'Data_17'\n",
    "    ]\n",
    "\n",
    "class SignalProcessor:\n",
    "    \"\"\"Smoothes input data for more stable detection.\"\"\"\n",
    "    def __init__(self, alpha=0.3):\n",
    "        self.alpha = alpha\n",
    "        self.smoothed_input = None\n",
    "\n",
    "    def smooth_input(self, raw):\n",
    "        raw_arr = np.array(raw)\n",
    "        if self.smoothed_input is None: self.smoothed_input = raw_arr\n",
    "        else: self.smoothed_input = (self.alpha * raw_arr) + ((1 - self.alpha) * self.smoothed_input)\n",
    "        return self.smoothed_input.tolist()\n",
    "\n",
    "# ==================== LIVE INTERFACE ====================\n",
    "class LiveInterface:\n",
    "    def __init__(self, model, scaler):\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "        self.client = mqtt.Client()\n",
    "        self.filter = SignalProcessor(alpha=0.3)\n",
    "        self.logs = []\n",
    "\n",
    "    def on_connect(self, client, userdata, flags, rc):\n",
    "        print(\"[MQTT] Connected to Live Interface. Monitoring...\")\n",
    "        client.subscribe(LIVE_FEATURES_TOPIC)\n",
    "\n",
    "    # Plotting Function\n",
    "    def plot_latency_histogram(self, df):\n",
    "        if 'Latency_ms' not in df.columns: return\n",
    "\n",
    "        latencies = df['Latency_ms'].dropna()\n",
    "        if len(latencies) == 0: return\n",
    "\n",
    "        mean_val = np.mean(latencies)\n",
    "        median_val = np.median(latencies)\n",
    "        p95_val = np.percentile(latencies, 95)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Standard bins 0-400ms \n",
    "        bins_list = np.arange(0, 401, 20) \n",
    "        plt.hist(latencies, bins=bins_list, color='#72a2c6', edgecolor='black', alpha=0.8)\n",
    "        \n",
    "        plt.axvline(mean_val, color='red', linestyle='dashed', linewidth=2, label=f'Mean = {mean_val:.2f} ms')\n",
    "        plt.axvline(median_val, color='blue', linestyle='dashed', linewidth=2, label=f'Median = {median_val:.2f} ms')\n",
    "        plt.axvline(p95_val, color='green', linestyle='dashed', linewidth=2, label=f'P95 = {p95_val:.2f} ms')\n",
    "        \n",
    "        plt.xlim(0, 400)\n",
    "        \n",
    "        plt.title(f'Detection Latency Distribution ({len(latencies):,} samples)', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Detection Latency (milliseconds)', fontsize=12)\n",
    "        plt.ylabel('Frequency (count)', fontsize=12)\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.3)\n",
    "        \n",
    "        save_path = os.path.join(DATA_DIR, 'latency_histogram_detection.png')\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        print(f\"[GRAPH] Latency histogram saved to: {save_path}\")\n",
    "        plt.close()\n",
    "\n",
    "    def on_message(self, client, userdata, msg):\n",
    "        try:\n",
    "            # Start Timer\n",
    "            t_start = time.time()\n",
    "            \n",
    "            payload = json.loads(msg.payload.decode())\n",
    "            sim_time = float(payload.get(\"Time\", 0))\n",
    "            feat = payload.get(\"features\", {})\n",
    "            if not feat: return\n",
    "            \n",
    "            # Extract Raw Data for Soft Sensor display \n",
    "            raw_lac = float(feat.get('Data_1', 20.0))\n",
    "            raw_ade = float(feat.get('Data_2', 4.0))\n",
    "\n",
    "            if sim_time < WARMUP_TIME:\n",
    "                print(f\"T={sim_time:06.2f} | Status: WARMING UP...\", end='\\r')\n",
    "                return\n",
    "\n",
    "            # Prepare Features\n",
    "            cols = get_shap_features()\n",
    "            ai_input = [float(feat.get(c, 0)) for c in cols]\n",
    "            \n",
    "            # --- DETECTION LOGIC  ---\n",
    "            smoothed = self.filter.smooth_input(ai_input)\n",
    "            vec = self.scaler.transform(np.array(smoothed).reshape(1, -1))\n",
    "            \n",
    "            # Get Probabilities\n",
    "            probs = self.model.predict_proba(vec)[0]\n",
    "            pred = int(np.argmax(probs))\n",
    "            vote_name = CLASS_NAMES[pred]\n",
    "            \n",
    "            # --- SIMULINK BRIDGE ---\n",
    "            # 1. Publish Prediction\n",
    "            self.client.publish(LIVE_RESULT_TOPIC, json.dumps({\n",
    "                \"fault_id\": pred,\n",
    "                \"locked_id\": 0 \n",
    "            }))\n",
    "\n",
    "            # 2. Publish Soft Sensors\n",
    "            try:\n",
    "                self.client.publish(TOPIC_SOFT_SENSOR, json.dumps({\n",
    "                    \"soft_lactose\": round(smoothed[0], 4), \n",
    "                    \"soft_adenine\": round(smoothed[1], 4)\n",
    "                }))\n",
    "            except: pass\n",
    "\n",
    "            # 3. Force Actuators to 0 \n",
    "            self.send_ctrl(0.0, 0, \"MONITORING\", \"AI_Lactose_Actuator\")\n",
    "            self.send_ctrl(0.0, 0, \"MONITORING\", \"AI_Adenine_Actuator\")\n",
    "            \n",
    "            # End Timer & Calculate Latency\n",
    "            t_end = time.time()\n",
    "            latency_ms = (t_end - t_start) * 1000\n",
    "\n",
    "            # Display\n",
    "            print(f\"T={sim_time:06.2f} | Detected: {vote_name} (ID: {pred}) | Lat: {latency_ms:.2f}ms   \", end='\\r')\n",
    "\n",
    "            # --- LOGGING ---\n",
    "            log_entry = {\n",
    "                \"Time\": sim_time,\n",
    "                \"Final_Vote\": pred,\n",
    "                \"Vote_Name\": vote_name,\n",
    "                \"Latency_ms\": latency_ms \n",
    "            }\n",
    "            # Add separate columns for each confidence score\n",
    "            for i, prob in enumerate(probs):\n",
    "                log_entry[f\"Conf_OM{i}\"] = prob\n",
    "                \n",
    "            self.logs.append(log_entry)\n",
    "            \n",
    "            # --- SHUTDOWN & SAVE ---\n",
    "            if sim_time >= 120.0:\n",
    "                self.save_and_exit()\n",
    "\n",
    "        except Exception as e: print(e)\n",
    "\n",
    "    def send_ctrl(self, val, fid, reason, target):\n",
    "        try:\n",
    "            payload = {\"action\": \"SET_PARAM\", \"target_block\": target, \"value\": str(val), \"fault_id\": fid, \"reason\": reason}\n",
    "            self.client.publish(TOPIC_CONTROL, json.dumps(payload))\n",
    "        except: pass\n",
    "\n",
    "    def save_and_exit(self):\n",
    "        print(\"\\n\\n[INFO] Simulation finished. Saving Data & Graph...\")\n",
    "        \n",
    "        # Convert list to DataFrame\n",
    "        df = pd.DataFrame(self.logs)\n",
    "        \n",
    "        # Reorder columns: Time | Final_Vote | Vote_Name | Latency_ms | Conf_OM0...\n",
    "        fixed_cols = ['Time', 'Final_Vote', 'Vote_Name', 'Latency_ms'] + [f'Conf_OM{i}' for i in range(9)]\n",
    "        df = df[fixed_cols]\n",
    "        \n",
    "        # Save Excel\n",
    "        save_path = os.path.join(DATA_DIR, 'detection_log.xlsx')\n",
    "        df.to_excel(save_path, index=False)\n",
    "        print(f\"[SUCCESS] Excel saved to: {save_path}\")\n",
    "        \n",
    "        # Save Graph\n",
    "        self.plot_latency_histogram(df)\n",
    "        \n",
    "        self.client.disconnect()\n",
    "        sys.exit(0)\n",
    "\n",
    "    def start(self):\n",
    "        self.client.on_connect = self.on_connect\n",
    "        self.client.on_message = self.on_message\n",
    "        self.client.connect(MQTT_BROKER, MQTT_PORT, 60)\n",
    "        print(\"=\"*50)\n",
    "        print(\" LIVE INTERFACE ACTIVE (Monitoring + Logging + Latency)\")\n",
    "        print(\"=\"*50)\n",
    "        self.client.loop_forever()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if os.path.exists(os.path.join(DATA_DIR, 'rf_model.pkl')):\n",
    "        model = joblib.load(os.path.join(DATA_DIR, 'rf_model.pkl'))\n",
    "        scaler = joblib.load(os.path.join(DATA_DIR, 'rf_scaler.pkl'))\n",
    "        LiveInterface(model, scaler).start()\n",
    "    else:\n",
    "        print(\"[ERR] Model not found! Please run training first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8cdf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this code to control the actuation based on the faults \n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import paho.mqtt.client as mqtt\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque, Counter\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==================== CONFIGURATION ====================\n",
    "DATA_DIR = r'File DIrectoty Address'----------> Put the directory address where all the necessary files are saved\n",
    "AGENTS_DIR = os.path.join(DATA_DIR, 'agents')\n",
    "MQTT_BROKER = 'localhost'\n",
    "MQTT_PORT = 1883\n",
    "\n",
    "TOPIC_FEATURES = 'fault_detection/live/features'\n",
    "TOPIC_PREDICTION = 'fault_detection/live/prediction'\n",
    "TOPIC_CONTROL = 'fault_detection/live/control'\n",
    "TOPIC_SOFT_SENSOR = 'fault_detection/live/soft_sensor' \n",
    "\n",
    "NOMINAL_DATA1 = 20.0 \n",
    "NOMINAL_DATA2 = 4.0\n",
    "FAULT_START_TIME = 10.0\n",
    "DECISION_TIME = 30.0\n",
    "\n",
    "# ==================== 1. AGENTS ====================\n",
    "class FaultAgent:\n",
    "    def __init__(self, agent_id, model_path):\n",
    "        self.id = agent_id\n",
    "        try: self.model = joblib.load(model_path)\n",
    "        except: self.model = None\n",
    "\n",
    "    def evaluate(self, features):\n",
    "        if self.model is None: return {\"agent_id\": self.id, \"is_match\": False, \"confidence\": 0.0}\n",
    "        probs = self.model.predict_proba(features)[0]\n",
    "        return {\"agent_id\": self.id, \"is_match\": probs[1] > 0.5, \"confidence\": probs[1]}\n",
    "\n",
    "class SystemCoordinator:\n",
    "    def __init__(self, scaler):\n",
    "        self.scaler = scaler\n",
    "        self.agents = []\n",
    "        self.load_agents()\n",
    "\n",
    "    def load_agents(self):\n",
    "        for i in range(9):\n",
    "            path = os.path.join(AGENTS_DIR, f'agent_{i}.pkl')\n",
    "            if os.path.exists(path): self.agents.append(FaultAgent(i, path))\n",
    "\n",
    "    def consult_agents(self, raw_features):\n",
    "        X = self.scaler.transform(np.array(raw_features).reshape(1, -1))\n",
    "        reports = [agent.evaluate(X) for agent in self.agents]\n",
    "        active = [r for r in reports if r['is_match']]\n",
    "        if not active: return max(reports, key=lambda x: x['confidence'])['agent_id'], 0.0\n",
    "        return max(active, key=lambda x: x['confidence'])['agent_id'], max(active, key=lambda x: x['confidence'])['confidence']\n",
    "\n",
    "# ==================== 2. Exponentially Weighted Moving Average Filter ====================\n",
    "class UltraHeavyEWMAFilter:\n",
    "    def __init__(self, start_value=0.0):\n",
    "        self.alpha = 0.001   \n",
    "        self.x = start_value \n",
    "\n",
    "    def update(self, z):\n",
    "        self.x = (self.alpha * z) + ((1 - self.alpha) * self.x)\n",
    "        return self.x\n",
    "\n",
    "# ==================== 3. CONTROL MANAGER ====================\n",
    "class ControlManager:\n",
    "    def __init__(self, mqtt_client):\n",
    "        self.client = mqtt_client\n",
    "        \n",
    "        # Use List (Not Deque) to capture ALL votes from T10-T30\n",
    "        self.vote_buffer = [] \n",
    "        \n",
    "        self.locked_fault = None\n",
    "        \n",
    "        # Initialize Soft Sensors\n",
    "        self.soft_lac = UltraHeavyEWMAFilter(start_value=NOMINAL_DATA1) \n",
    "        self.soft_ade = UltraHeavyEWMAFilter(start_value=NOMINAL_DATA2)\n",
    "        \n",
    "        # State Memory\n",
    "        self.AI_Lactose_Actuator = 0.0\n",
    "        self.AI_Adenine_Actuator = 0.0\n",
    "        \n",
    "        self.MAX_RATE_CHANGE = 0.2 \n",
    "\n",
    "    def execute(self, sim_time, consensus_id, data1, data2):\n",
    "        # 1. Update Filters\n",
    "        pv_lac = self.soft_lac.update(data1)\n",
    "        pv_ade = self.soft_ade.update(data2)\n",
    "\n",
    "        # 2. Publish CLEAN Values\n",
    "        try:\n",
    "            self.client.publish(TOPIC_SOFT_SENSOR, json.dumps({\n",
    "                \"soft_lactose\": round(pv_lac, 4),\n",
    "                \"soft_adenine\": round(pv_ade, 4),\n",
    "                \"fault_id\": int(consensus_id)\n",
    "            }))\n",
    "        except: pass\n",
    "\n",
    "        # --- PHASE 1: OBSERVATION ---\n",
    "        if sim_time < DECISION_TIME:\n",
    "            # Only count votes if T >= 10.0 (Ignore start noise)\n",
    "            if sim_time >= FAULT_START_TIME and consensus_id != 0: \n",
    "                self.vote_buffer.append(consensus_id)\n",
    "            \n",
    "            # Send Locked ID as 0 during observation\n",
    "            self.send_pred(consensus_id, 0)\n",
    "            self.send_ctrl(0.0, 0, \"OBSERVING\", \"AI_Lactose_Actuator\")\n",
    "            self.send_ctrl(0.0, 0, \"OBSERVING\", \"AI_Adenine_Actuator\")\n",
    "            return\n",
    "\n",
    "        # --- PHASE 2: LOCKING ---\n",
    "        if self.locked_fault is None:\n",
    "            if self.vote_buffer:\n",
    "                # Count all votes collected between T=10 and T=30\n",
    "                self.locked_fault = Counter(self.vote_buffer).most_common(1)[0][0]\n",
    "                print(f\"\\n[MANAGER] Locked on FAULT {self.locked_fault}\\n\")\n",
    "            else:\n",
    "                self.locked_fault = 0\n",
    "\n",
    "        # Send the Locked ID \n",
    "        self.send_pred(consensus_id, self.locked_fault) \n",
    "\n",
    "        # --- PHASE 3: ACTUATION ---\n",
    "        fid = self.locked_fault\n",
    "        \n",
    "        # --- BLOCK A: LACTOSE CONTROL (Faults 1, 2, 3, 4) ---\n",
    "        if 1 <= fid <= 4:\n",
    "            next_val = 0.0\n",
    "            \n",
    "            # === FAULT 4: NOISE ===\n",
    "            if fid == 4:\n",
    "                error = NOMINAL_DATA1 - pv_lac\n",
    "                if abs(error) < 1.0:\n",
    "                     next_val = 0.0 \n",
    "                else:\n",
    "                     Kp = 0.5 \n",
    "                raw_act = error * Kp\n",
    "                     delta = raw_act - self.AI_Lactose_Actuator\n",
    "                     delta = np.clip(delta, -self.MAX_RATE_CHANGE, self.MAX_RATE_CHANGE)\n",
    "                    next_val = self.AI_Lactose_Actuator + delta\n",
    "\n",
    "            # === FAULT 3: PULSE ===\n",
    "            elif fid == 3:\n",
    "                \n",
    "                if (30.0 <= sim_time < 60.0) or (80.0 <= sim_time < 120.0):\n",
    "                    next_val = 20.0\n",
    "                else:\n",
    "                    next_val = 0.0\n",
    "\n",
    "            # === FAULTS 1 & 2 ===\n",
    "            else:\n",
    "                dt = sim_time - FAULT_START_TIME\n",
    "                if fid == 1: next_val = 4.0\n",
    "                elif fid == 2: next_val = 0.2 * dt\n",
    "\n",
    "            next_val = np.clip(next_val, -60, 60)\n",
    "            self.AI_Lactose_Actuator = next_val\n",
    "            self.AI_Adenine_Actuator = 0.0\n",
    "            \n",
    "            self.send_ctrl(self.AI_Lactose_Actuator, fid, \"EXECUTING\", \"AI_Lactose_Actuator\")\n",
    "            self.send_ctrl(self.AI_Adenine_Actuator, fid, \"LOCKED\", \"AI_Adenine_Actuator\")\n",
    "\n",
    "\n",
    "        # --- BLOCK B: ADENINE CONTROL (Faults 5, 6, 7, 8) ---\n",
    "        elif 5 <= fid <= 8:\n",
    "            next_val = 0.0\n",
    "            \n",
    "            if fid == 8:\n",
    "                error = NOMINAL_DATA2 - pv_ade\n",
    "                if abs(error) < 0.05:\n",
    "                    next_val = 0.0\n",
    "                else:\n",
    "                    Kp = 1.0  \n",
    "                    raw_act = error * Kp\n",
    "                    delta = raw_act - self.AI_Adenine_Actuator\n",
    "                    delta = np.clip(delta, -self.MAX_RATE_CHANGE, self.MAX_RATE_CHANGE)\n",
    "                    next_val = self.AI_Adenine_Actuator + delta\n",
    "            \n",
    "            # === FAULT 7: TIME BASED ===\n",
    "            elif fid == 7:\n",
    "                if (30.0 <= sim_time < 60.0) or (80.0 <= sim_time < 120.0):\n",
    "                    next_val = 4.0  \n",
    "                else:\n",
    "                    next_val = 0.0\n",
    "            \n",
    "            else:\n",
    "                dt = sim_time - FAULT_START_TIME\n",
    "                if fid == 5: next_val = -0.8\n",
    "                elif fid == 6: next_val = -0.05 * dt\n",
    "\n",
    "            next_val = np.clip(next_val, -60, 60)\n",
    "            self.AI_Adenine_Actuator = next_val\n",
    "            self.AI_Lactose_Actuator = 0.0\n",
    "            \n",
    "            self.send_ctrl(self.AI_Adenine_Actuator, fid, \"EXECUTING\", \"AI_Adenine_Actuator\")\n",
    "            self.send_ctrl(self.AI_Lactose_Actuator, fid, \"LOCKED\", \"AI_Lactose_Actuator\")\n",
    "\n",
    "        # --- BLOCK C: NO FAULT ---\n",
    "        else:\n",
    "            self.AI_Lactose_Actuator = 0.0\n",
    "            self.AI_Adenine_Actuator = 0.0\n",
    "            self.send_ctrl(0.0, 0, \"NORMAL\", \"AI_Lactose_Actuator\")\n",
    "            self.send_ctrl(0.0, 0, \"NORMAL\", \"AI_Adenine_Actuator\")\n",
    "\n",
    "    def send_pred(self, live_val, locked_val):\n",
    "        msg = {\n",
    "            \"fault_id\": int(live_val),\n",
    "            \"locked_id\": int(locked_val)\n",
    "        }\n",
    "        self.client.publish(TOPIC_PREDICTION, json.dumps(msg))\n",
    "\n",
    "    def send_ctrl(self, val, fid, reason, target):\n",
    "        payload = {\"action\": \"SET_PARAM\", \"target_block\": target, \"value\": str(round(val, 4)), \"fault_id\": fid, \"reason\": reason}\n",
    "        self.client.publish(TOPIC_CONTROL, json.dumps(payload))\n",
    "\n",
    "# ==================== 4. MAIN BRIDGE ====================\n",
    "class MAS_Bridge:\n",
    "    def __init__(self):\n",
    "        self.client = mqtt.Client()\n",
    "        scaler_path = os.path.join(DATA_DIR, 'global_scaler.pkl')\n",
    "        if not os.path.exists(scaler_path): raise Exception(\"Scaler missing.\")\n",
    "        self.scaler = joblib.load(scaler_path)\n",
    "        \n",
    "        self.coordinator = SystemCoordinator(self.scaler)\n",
    "        self.manager = ControlManager(self.client)\n",
    "        self.alpha = 0.3\n",
    "        self.smooth_vec = None\n",
    "        self.logs = []\n",
    "\n",
    "    def on_connect(self, client, userdata, flags, rc):\n",
    "        print(f\"[MQTT] Connected. Agents listening...\")\n",
    "        client.subscribe(TOPIC_FEATURES)\n",
    "\n",
    "    # [FIXED INDENTATION FOR PLOT FUNCTION]\n",
    "    def plot_latency_histogram(self, df):\n",
    "        if 'Latency_ms' not in df.columns: return\n",
    "\n",
    "        latencies = df['Latency_ms'].dropna()\n",
    "        if len(latencies) == 0: return\n",
    "\n",
    "        mean_val = np.mean(latencies)\n",
    "        median_val = np.median(latencies)\n",
    "        p95_val = np.percentile(latencies, 95)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(latencies, bins=30, color='#72a2c6', edgecolor='black', alpha=0.8)\n",
    "        \n",
    "        plt.axvline(mean_val, color='red', linestyle='dashed', linewidth=2, label=f'Mean = {mean_val:.2f} ms')\n",
    "        plt.axvline(median_val, color='blue', linestyle='dashed', linewidth=2, label=f'Median = {median_val:.2f} ms')\n",
    "        plt.axvline(p95_val, color='green', linestyle='dashed', linewidth=2, label=f'P95 = {p95_val:.2f} ms')\n",
    "        \n",
    "        plt.title(f'Detection Latency Distribution ({len(latencies):,} samples)', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Detection Latency (milliseconds)', fontsize=12)\n",
    "        plt.ylabel('Frequency (count)', fontsize=12)\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.3)\n",
    "        \n",
    "        save_path = os.path.join(DATA_DIR, 'latency_histogram.png')\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        print(f\"[GRAPH] Latency histogram saved to: {save_path}\")\n",
    "        plt.close()\n",
    "\n",
    "    \n",
    "    def on_message(self, client, userdata, msg):\n",
    "        try:\n",
    "            t_start = time.time() # Start timer\n",
    "            \n",
    "            payload = json.loads(msg.payload.decode())\n",
    "            sim_time = float(payload.get(\"Time\", 0))\n",
    "            feat = payload.get(\"features\", {})\n",
    "            if not feat: return\n",
    "\n",
    "            cols = ['Data_1', 'Data_2', 'Data_3', 'Data_4', 'Data_5', 'Data_6', 'Data_7', 'Data_8', 'Data_9', 'Data_10', 'Data_11', 'Data_12', 'Data_13', 'Data_14', 'Data_15', 'Data_16', 'Data_17']\n",
    "            raw = [float(feat.get(c, 0)) for c in cols]\n",
    "            \n",
    "            if self.smooth_vec is None: self.smooth_vec = np.array(raw)\n",
    "            else: self.smooth_vec = (self.alpha * np.array(raw)) + ((1 - self.alpha) * self.smooth_vec)\n",
    "\n",
    "            winner_id, confidence = self.coordinator.consult_agents(self.smooth_vec)\n",
    "            self.manager.execute(sim_time, winner_id, raw[0], raw[1]) \n",
    "            \n",
    "            # End Timer\n",
    "            t_end = time.time()\n",
    "            latency_ms = (t_end - t_start) * 1000\n",
    "\n",
    "            # Debug\n",
    "            locked_status = self.manager.locked_fault if self.manager.locked_fault is not None else 0\n",
    "            print(f\"[T={sim_time:06.1f}] Live:{winner_id} | Locked:{locked_status} | LacAct:{self.manager.AI_Lactose_Actuator:.2f} | Lat:{latency_ms:.2f}ms\", end='\\r')\n",
    "            \n",
    "            self.logs.append({\n",
    "                \"Time\": sim_time, \n",
    "                \"Fault\": winner_id, \n",
    "                \"AI_Lactose_Actuator\": self.manager.AI_Lactose_Actuator, \n",
    "                \"AI_Adenine_Actuator\": self.manager.AI_Adenine_Actuator,\n",
    "                \"Latency_ms\": latency_ms\n",
    "            })\n",
    "            \n",
    "            if sim_time >= 120.0: self.shutdown()\n",
    "\n",
    "        except Exception as e: print(f\"\\n[ERR] {e}\")\n",
    "\n",
    "    def shutdown(self):\n",
    "        print(\"\\n[MAS] Simulation finished. Saving data...\")\n",
    "        # Save Main Logs\n",
    "        df_logs = pd.DataFrame(self.logs)\n",
    "        df_logs.to_excel(os.path.join(DATA_DIR, 'mas_logs_final.xlsx'), index=False)\n",
    "        \n",
    "        # Use df_logs for plotting (MAS code uses self.logs, not self.control_log)\n",
    "        self.plot_latency_histogram(df_logs)\n",
    "        \n",
    "        self.client.disconnect()\n",
    "        sys.exit(0)\n",
    "\n",
    "    def start(self):\n",
    "        self.client.on_connect = self.on_connect\n",
    "        self.client.on_message = self.on_message\n",
    "        self.client.connect(MQTT_BROKER, MQTT_PORT, 60)\n",
    "        self.client.loop_forever()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*60)\n",
    "    print(\" CONTROL with FaultID based on T10 to T30 vote\")\n",
    "    print(\"=\"*60)\n",
    "    bridge = MAS_Bridge()\n",
    "    bridge.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a0173e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
